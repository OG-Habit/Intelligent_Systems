{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Analysis\n",
    "---\n",
    "- Churn refers to the number of customers who stop doing business with a company within a given time period. <br><br>\n",
    "- A high churn rate can be a sign of customer dissatisfaction or a problem with the company's products or services. It can also be caused by factors outside of the company's control, such as a competitor offering a better deal.<br><br>\n",
    "- Churning customers can have a number of economic disadvantages for a business, including:<br>\n",
    "    - Loss of revenue. When customers churn, they stop paying for the company's products or services. This can lead to a significant loss of revenue, especially for businesses that rely on recurring revenue.<br><br>\n",
    "    - Increased marketing costs. To replace lost customers, businesses often need to spend more on marketing and sales. This can be a significant expense, especially for businesses with a high churn rate.<br><br>\n",
    "    - Damage to brand reputation. When customers churn, they may spread negative word-of-mouth about the company. This can damage the company's brand reputation and make it more difficult to attract new customers.<br><br>\n",
    "    - Increased customer acquisition costs. It is more expensive to acquire new customers than to retain existing customers. This is because new customers are less likely to be familiar with the company's products or services and may require more hand-holding.<br><br>\n",
    "    - Decreased customer lifetime value. The customer lifetime value (CLV) is the total amount of money that a customer is expected to spend with a company over their lifetime. When customers churn, the company loses out on the potential future revenue that they could have generated from that customer.<br><br>\n",
    "\n",
    "- The economic disadvantages of churning customers can be significant, so it is important for businesses to take steps to reduce churn. Some common ways to reduce churn include:<br><br>\n",
    "\n",
    "    - Providing excellent customer service. This means being responsive to customer inquiries, resolving problems quickly and efficiently, and going the extra mile to make sure that customers are satisfied.<br><br>\n",
    "    - Offering competitive prices. This means keeping prices in line with the competition and offering discounts and promotions to encourage customers to stay with the company.<br><br>\n",
    "    - Constantly innovating. This means keeping up with the latest trends and offering new and improved products and services to keep customers engaged.<br><br>\n",
    "    - Personalizing the customer experience. This means getting to know each customer's individual needs and preferences and tailoring the company's offerings accordingly.\n",
    "<br><br>\n",
    "- By taking steps to reduce churn, businesses can improve their bottom line and ensure long-term success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('bank_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CreditScore Geography  Gender Age Tenure    Balance NumOfProducts  \\\n",
       "0            619    France  Female  42      2        0.0             1   \n",
       "1            608     Spain  Female  41      1   83807.86             1   \n",
       "2            502    France  Female  42      8   159660.8             3   \n",
       "3            699    France  Female  39      1        0.0             2   \n",
       "4            850     Spain  Female  43      2  125510.82             1   \n",
       "...          ...       ...     ...  ..    ...        ...           ...   \n",
       "9995         771    France    Male  39      5        0.0             2   \n",
       "9996         516    France    Male  35     10   57369.61             1   \n",
       "9997         709    France  Female  36      7        0.0             1   \n",
       "9998         772   Germany    Male  42      3   75075.31             2   \n",
       "9999         792    France  Female  28      4  130142.79             1   \n",
       "\n",
       "     HasCrCard IsActiveMember EstimatedSalary  \n",
       "0            1              1       101348.88  \n",
       "1            0              1       112542.58  \n",
       "2            1              0       113931.57  \n",
       "3            0              0        93826.63  \n",
       "4            1              1         79084.1  \n",
       "...        ...            ...             ...  \n",
       "9995         1              0        96270.64  \n",
       "9996         1              1       101699.77  \n",
       "9997         0              1        42085.58  \n",
       "9998         1              0        92888.52  \n",
       "9999         1              0        38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X, columns = [\"CreditScore\",\"Geography\",\"Gender\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"HasCrCard\",\"IsActiveMember\",\"EstimatedSalary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y, columns = [\"Exited\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "VYP9cQTWbzuI",
    "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "38vKGE6Nb2RR",
    "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6bQ0UgSU-NJ"
   },
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le5MJreAbW52"
   },
   "source": [
    "Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxVKWXxLbczC"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "-M1KboxFb6OO",
    "outputId": "e2b8c7e8-0cbc-4cdf-f4eb-7f0853a00b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUxGZezpbMcb"
   },
   "source": [
    "One Hot Encoding the \"Geography\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMXC8-KMVirw"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "ZcxwEon-b8nV",
    "outputId": "23a98af4-5e33-4b26-c27b-f06e3c5d2baf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, ..., 1, 1, 101348.88],\n",
       "       [0.0, 0.0, 1.0, ..., 0, 1, 112542.58],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [1.0, 0.0, 0.0, ..., 0, 1, 42085.58],\n",
       "       [0.0, 1.0, 0.0, ..., 1, 0, 92888.52],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.6185 - accuracy: 0.7371\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 882us/step - loss: 0.4802 - accuracy: 0.8004\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 916us/step - loss: 0.4446 - accuracy: 0.8077\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 983us/step - loss: 0.4309 - accuracy: 0.8135\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4236 - accuracy: 0.8170\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8196\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 947us/step - loss: 0.4082 - accuracy: 0.8253\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 900us/step - loss: 0.3974 - accuracy: 0.8345\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 926us/step - loss: 0.3858 - accuracy: 0.8439\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 909us/step - loss: 0.3764 - accuracy: 0.8476\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 882us/step - loss: 0.3697 - accuracy: 0.8501\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 863us/step - loss: 0.3643 - accuracy: 0.8506\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 876us/step - loss: 0.3603 - accuracy: 0.8505\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 879us/step - loss: 0.3569 - accuracy: 0.8525\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 904us/step - loss: 0.3543 - accuracy: 0.8533\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 907us/step - loss: 0.3518 - accuracy: 0.8549\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8522\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8568\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 903us/step - loss: 0.3467 - accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 844us/step - loss: 0.3457 - accuracy: 0.8570\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 892us/step - loss: 0.3448 - accuracy: 0.8583\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 848us/step - loss: 0.3435 - accuracy: 0.8576\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 870us/step - loss: 0.3428 - accuracy: 0.8593\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 837us/step - loss: 0.3422 - accuracy: 0.8599\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 844us/step - loss: 0.3416 - accuracy: 0.8611\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 878us/step - loss: 0.3408 - accuracy: 0.8618\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 895us/step - loss: 0.3404 - accuracy: 0.8605\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8608\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 930us/step - loss: 0.3399 - accuracy: 0.8610\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 844us/step - loss: 0.3397 - accuracy: 0.8615\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 943us/step - loss: 0.3396 - accuracy: 0.8605\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 950us/step - loss: 0.3394 - accuracy: 0.8629\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 857us/step - loss: 0.3389 - accuracy: 0.8622\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 862us/step - loss: 0.3388 - accuracy: 0.8619\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 874us/step - loss: 0.3386 - accuracy: 0.8634\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 896us/step - loss: 0.3383 - accuracy: 0.8620\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 868us/step - loss: 0.3380 - accuracy: 0.8635\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 871us/step - loss: 0.3377 - accuracy: 0.8616\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 877us/step - loss: 0.3376 - accuracy: 0.8619\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 861us/step - loss: 0.3374 - accuracy: 0.8621\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 881us/step - loss: 0.3371 - accuracy: 0.8629\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 881us/step - loss: 0.3371 - accuracy: 0.8622\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 849us/step - loss: 0.3367 - accuracy: 0.8625\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 925us/step - loss: 0.3368 - accuracy: 0.8618\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 897us/step - loss: 0.3363 - accuracy: 0.8631\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 903us/step - loss: 0.3363 - accuracy: 0.8629\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 886us/step - loss: 0.3360 - accuracy: 0.8626\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 916us/step - loss: 0.3359 - accuracy: 0.8637\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 908us/step - loss: 0.3357 - accuracy: 0.8627\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 886us/step - loss: 0.3357 - accuracy: 0.8624\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 913us/step - loss: 0.3354 - accuracy: 0.8618\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8622\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 912us/step - loss: 0.3348 - accuracy: 0.8631\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 890us/step - loss: 0.3353 - accuracy: 0.8635\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 852us/step - loss: 0.3344 - accuracy: 0.8629\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 853us/step - loss: 0.3346 - accuracy: 0.8634\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 841us/step - loss: 0.3350 - accuracy: 0.8639\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 838us/step - loss: 0.3342 - accuracy: 0.8646\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 891us/step - loss: 0.3339 - accuracy: 0.8645\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 885us/step - loss: 0.3345 - accuracy: 0.8643\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 922us/step - loss: 0.3339 - accuracy: 0.8633\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 976us/step - loss: 0.3343 - accuracy: 0.8640\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 864us/step - loss: 0.3340 - accuracy: 0.8640\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 940us/step - loss: 0.3338 - accuracy: 0.8637\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 863us/step - loss: 0.3338 - accuracy: 0.8633\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 926us/step - loss: 0.3332 - accuracy: 0.8635\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 895us/step - loss: 0.3338 - accuracy: 0.8648\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 899us/step - loss: 0.3336 - accuracy: 0.8627\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 871us/step - loss: 0.3334 - accuracy: 0.8641\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 877us/step - loss: 0.3330 - accuracy: 0.8635\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 913us/step - loss: 0.3335 - accuracy: 0.8633\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 859us/step - loss: 0.3327 - accuracy: 0.8655\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 851us/step - loss: 0.3332 - accuracy: 0.8636\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8635\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 837us/step - loss: 0.3329 - accuracy: 0.8644\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 896us/step - loss: 0.3328 - accuracy: 0.8651\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 871us/step - loss: 0.3325 - accuracy: 0.8637\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 844us/step - loss: 0.3328 - accuracy: 0.8650\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 880us/step - loss: 0.3325 - accuracy: 0.8644\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 861us/step - loss: 0.3327 - accuracy: 0.8635\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8633\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 875us/step - loss: 0.3324 - accuracy: 0.8641\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 894us/step - loss: 0.3324 - accuracy: 0.8644\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 924us/step - loss: 0.3321 - accuracy: 0.8643\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 945us/step - loss: 0.3323 - accuracy: 0.8633\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 944us/step - loss: 0.3321 - accuracy: 0.8648\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8631\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8629\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 932us/step - loss: 0.3320 - accuracy: 0.8633\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 889us/step - loss: 0.3317 - accuracy: 0.8649\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 840us/step - loss: 0.3320 - accuracy: 0.8643\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 908us/step - loss: 0.3316 - accuracy: 0.8649\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 847us/step - loss: 0.3319 - accuracy: 0.8648\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 837us/step - loss: 0.3313 - accuracy: 0.8652\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8646\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 825us/step - loss: 0.3313 - accuracy: 0.8643\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 823us/step - loss: 0.3315 - accuracy: 0.8640\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 842us/step - loss: 0.3314 - accuracy: 0.8641\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 890us/step - loss: 0.3314 - accuracy: 0.8643\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 864us/step - loss: 0.3314 - accuracy: 0.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29be7049c50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Part 4 - Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ci6K_r6LaF6P",
    "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1514   81]\n",
      " [ 201  204]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.859"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoUAAAKqCAYAAABM0yQ3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABC6UlEQVR4nO3deVxVdeL/8fcBZBUQUHFH3JdKc83M1HJrUVOnTc21TNOy0Sxtc52xsu+kpr+y3Cu3TE3LxtQ0xzX31MSyXFEwRbhsgsD5/eFwRmIRLlyuwOv5ePCYy1k/99pcX557zzmGaZqmAAAAUKK5OHsAAAAAcD6iEAAAAEQhAAAAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAt5kjR47oiSeeUMWKFeXm5ibDMNS4cWOnjWfr1q0yDEOGYThtDMja6dOnrT+b06dPO3s4QJFHFALFUGpqqlasWKF+/fqpTp06KlOmjNzd3VW+fHndd999GjdunI4ePersYWZy6tQptW7dWl9++aUiIiLk7++v4OBglS1b1tlDK5LSg8kwDNWvX/+Wy+/duzfDOgMGDCjQ8Rw6dEgTJkzQ9OnTC3S7AAqGm7MHAKBg7d69W/3799evv/5qTStVqpR8fX115coV7dixQzt27NA777yjnj17aunSpXJ3d3fiiP9nzpw5io2NVa1atbR161ZVrlzZ2UOSt7e36tat6+xh5FtYWJh27dqlVq1aZbvM/PnzHTqGQ4cOaeLEiQoJCdHLL7+c7+2VKlXK+rMpVapUvrcHlHQcKQSKkXXr1qldu3b69ddfFRQUpKlTp+rXX39VcnKyrly5ouTkZO3du1djx46Vn5+fVq1apYSEBGcP23LkyBFJUvfu3W+LIJSkFi1aKCwsTGFhYc4eit2qV68uSVqwYEG2y1y7dk3Lli2TYRgKCQkppJHlT+XKla0/m9vlvxegKCMKgWLit99+U9++fZWUlKQGDRro0KFDGjt2rGrXrm0t4+rqqmbNmmnq1Kk6deqUunfv7sQRZ5YeqKVLl3bySIqXfv36yTAMLV++PNt/BKxatUrR0dFq27atFZEAShaiECgm3nzzTdlsNnl6emr16tWqUqVKjssHBgZqzZo18vf3zzQvIiJCY8aMUcOGDeXj4yMfHx81bNhQr776qiIjI7Pc3l+/9B8ZGamRI0cqNDRUnp6eCg4O1lNPPZXlEbfq1avLMAxt3bpVkjRx4sQM321Lnz5hwgQZhqF27dpl+7xudWLInj171KdPH2tcPj4+CgkJUdu2bTV58mSdP38+T9tzxuuVV6GhoWrbtq1sNpu++uqrLJdJ/+h44MCBOW4rISFBS5cuVb9+/dS4cWOVK1dOHh4eqlSpkh577DF99913Wa5nGIa17TNnzmT48zUMQxMmTLCWHTBggPWdRtM0NXfuXN13330KCgqSYRhauHChpOxPNLly5YqqVKkiwzD02GOPZTmelJQUtW7dWoZh6K677tK1a9dyfN5AiWACKPIiIiJMFxcXU5I5ePDgfG1r69atZpkyZUxJpiTTx8fH9PHxsX4PCAgw//Of/2Ra79SpU9Yy33zzjVm+fHlTkunt7W16eHhY8/z8/MxDhw5lWLdZs2ZmcHCwWapUKWufwcHB1s+OHTtM0zTN8ePHm5LMtm3bZjv+LVu2WPv6q4ULF5qGYVjzPTw8TD8/P+t3SeaCBQtyvT1nvV65dfNzWrRokSnJbN++fablTp8+bRqGYfr6+prx8fFm27ZtTUlm//79My27YMECa7uGYZj+/v6mt7d3htdw9OjRmdYLDg62XmsXF5cMf77BwcHmtGnTrGX79+9vSjL79etn9urVy1onICDAdHFxsf6Mbn4NT506lWF/W7dutf4/MWvWrEzjeeONN0xJppeXl3ns2LG8vbBAMUUUAsXA0qVLMwSGvc6ePWsFToMGDczt27db87Zt22bWrVvXlGQGBgaa58+fz7DuzX9BBwQEmK1btzb37t1rmqZpXr9+3dy4caNZsWJFU5LZpk2bLPefHiPjx4/Pcn5+ojA+Pt709fU1JZl9+/Y1T548ac2Li4sz9+3bZ44ZM8b89ttvc7W92+H1upWbozD9+RuGYf7xxx8ZlpswYYIpyXz22WdN0zRzjMI1a9aYr7zyirl9+3YzPj7emn7hwgVz4sSJVth//fXXmdZND8qQkJAcx50ehaVLlzbd3NzM999/34yJiTFN0zRjY2PNCxcumKaZcxSapmm+9dZbpiTT09PT/Pnnn63pW7ZssYLx448/znEsQElCFALFwJtvvmn95RgeHm73doYOHWpFysWLFzPNP3funHW0Z/jw4Rnm3fwXdL169cyEhIRM669du9Za5ty5c5nmOzIK9+zZYx3Ju379erbr53Z7pun81+tW/nr089lnnzUlmW+//ba1TFpamlm9enVTknVENqcovJVp06aZkswHH3ww07y8RqEkc+bMmdkud6soTElJMVu3bm1Fe0JCgnn58mWzcuXKpiSzZ8+eeX16QLHGdwqBYuDKlSvW48DAQLu2YZqmVqxYIUkaOnSoKlSokGmZKlWqaOjQoZKkZcuWZbut0aNHy8vLK9P0hx56yLr8TfqZxoWlTJkykmSdiZ1fRfH1GjRokCRp0aJFMk1TkrRlyxadPn1adevW1b333pvvfTzyyCOSpF27dik1NTVf2woICNDzzz9v9/qurq5asmSJAgIC9Msvv2jkyJEaNGiQwsPDVbVqVc2dOzdf4wOKG6IQgKQbF46OioqSJHXo0CHb5Tp27CjpRoieOnUqy2VatmyZ5XQ3NzeVK1dOkqx9FZaaNWuqXr16un79ulq2bKl3331Xhw4dsjtciuLr1apVK9WrV09nzpzR5s2bJeX+BJObRUZGavz48WrVqpWCgoKsO88YhqEGDRpIunFCytWrV/M13ubNm+f7GprVqlXTp59+Kkn69NNPtXbtWrm6uurzzz9XQEBAvrYNFDdEIVAMBAUFWY/tjYdLly5Zj3O65tvNZzXfvM7NfH19s13fze3GNfOvX7+e1yHmi6urq5YtW6bQ0FCdOXNGY8eO1d133y0/Pz917NhRH330UZ6u2VhUX6/0+FuwYIFsNptWrVolV1dX9evXL1fr79q1S/Xq1dOkSZO0e/duRUVFycvLS+XLl89095n4+Ph8jbV8+fL5Wj9dr1691KtXL+v3V155Rffff3+BbBsoTohCoBho2LCh9fjgwYNOHMntrVGjRgoLC9NXX32lIUOG6I477lBiYqI2bdqkF154QfXq1Sv0j7UL2zPPPCNXV1etXr1aH3/8sRITE9WlSxdVrFjxluumpKTo6aefVnR0tBo3bqz169fLZrMpNjZWkZGRioiI0O7du63l0z+itperq2u+1k93+vRpbdq0yfp9x44d+f5oGyiOiEKgGGjfvr1cXG7833n16tV2bePmozJ/vVbfzW6eV1BHcnIr/ahZTteUi4mJyXEb7u7u6tmzp+bMmaMjR47ozz//1Mcff6zAwECdO3dO/fv3z9VYisLrlZWKFSuqS5cuSkxM1FtvvSUp9x8d79q1S2fOnJGrq6u++eYbPfTQQ5mOckZERBT4mPMjPWRjYmJUp04deXh4aPv27Zo8ebKzhwbcdohCoBgIDg62Ph5bsmRJhvse30r60ZzQ0FDrJJX075tlJf2IS1BQkEJDQ+0dsl3SvwN27ty5bJfZs2dPnrYZFBSk559/Xu+++66kG0dac3MiSlF4vbKTfsJJcnKyypYtq27duuVqvfTXvVy5ctl+ZH7zEbm/Sv+HS36PIObF+PHjtXv3bnl7e2vNmjXWn/OUKVO0ffv2QhsHUBQQhUAxMWXKFJUuXVqJiYnq2bOnwsPDc1z+6tWr6tWrl3VkzTAMPfnkk5KkOXPmZHnE58KFC5ozZ44k6emnny7gZ3BrjRo1ssaRVfxdunTJOqngr5KSknLc9s1n/6bHS06KwuuVna5du2rMmDEaPXq0pk+frlKlSuVqvfS730RGRmZ5p5bz589r5syZ2a7v5+cnSYqOjs77oO2wZcsWvfPOO5KkDz74QPXr19fIkSP1yCOPKDU1VX369Mn3yTBAcUIUAsVEnTp19Nlnn8nd3V3Hjh1T48aN9e677+rkyZPWMqmpqTp48KDefvtt1ahRQ6tWrcqwjddff11lypRRVFSUOnTooJ07d1rzduzYoQ4dOig6OlqBgYEaO3ZsoT23dPfee69CQkIkSf3799e+fftkmqbS0tK0detWtWvXTmlpaVmuu2zZMrVu3Vpz5szRH3/8YU1PTU3Vhg0brOfTqlWrXJ+Veru/XtkpVaqU3nvvPb3//vvq06dPrte777775OPjI9M09cQTT1hHpNNfw3bt2uV4O8A77rhDkmSz2azL+TjKlStX9MwzzygtLU09e/bUkCFDrHkLFixQxYoVdfbsWT333HMOHQdQpDjvEokAHGH79u1mrVq1Mtx2zN3d3QwMDLTu4qD/3qLs6aefNpOTkzOsv3XrVtPf3z/b27aVKVPG3LZtW6b93upCwulCQkKyvJ2cad764tWmaZr//ve/rbtm6L+3hfP09DQlmbVr185wd5eb3Xx7Nv33FndBQUEZXpNKlSqZx48fz7Bebm5z56zX61bSt5/XdXO6ePVHH32U4XUsXbq09fqXLVs2wwW3s3peDz74oDXf19fXDAkJMUNCQswPPvjAWib94tW3unh2Tq9ht27dTElm1apVzaioqEzrbty40brl4SeffJKLVwUo/jhSCBQzrVu3VlhYmJYuXao+ffqoVq1a8vT0VGxsrAIDA3XffffpjTfe0PHjx7VkyZJMHx22bdtWx48f1+jRo1W/fn2lpaXJNE3Vr19fr7zyio4fP642bdo46dlJnTt31n/+8x89+uijCggIUGpqqqpWraqxY8dq//79WV5EWpK6deumxYsXa+DAgWrUqJH8/f0VExMjX19ftWjRQpMnT9axY8dUr169PI3ndn+9CtrQoUP17bffql27dipdurRSUlJUuXJlvfjiizp8+LDuvPPOHNdfuXKl/v73v6tOnTq6fv26zpw5ozNnzhToR8qzZ8/W2rVr5eLiku31CDt06KAxY8ZIkl5++WUdP368wPYPFFWGaRbiN34BAABwW+JIIQAAAIhCAAAAEIUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYXALc2ePVvVq1eXp6enWrZsqZ9++snZQwJQAmzbtk1du3ZVpUqVZBiG1qxZ4+whoZgjCoEcLF++XKNGjdL48eN14MABNWrUSJ07d9alS5ecPTQAxVx8fLwaNWqk2bNnO3soKCG4zR2Qg5YtW6p58+aaNWuWJCktLU1Vq1bViy++qLFjxzp5dABKCsMwtHr1aj322GPOHgqKMY4UAtlITk7W/v371aFDB2uai4uLOnTooF27djlxZAAAFDyiEMjG5cuXlZqaquDg4AzTg4ODFRER4aRRAQDgGEQhAAAAiEIgO2XLlpWrq6siIyMzTI+MjFSFChWcNCoAAByDKASy4e7urqZNm2rz5s3WtLS0NG3evFmtWrVy4sgAACh4bs4eAHA7GzVqlPr3769mzZqpRYsWmj59uuLj4zVw4EBnDw1AMRcXF6eTJ09av586dUqHDh1SYGCgqlWr5sSRobjikjTALcyaNUvTpk1TRESEGjdurJkzZ6ply5bOHhaAYm7r1q1q3759pun9+/fXwoULC39AKPaIQgAAAPCdQgAAABCFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCORKUlKSJkyYoKSkJGcPBUAJw/sPCgvXKQRywWazyd/fXzExMfLz83P2cACUILz/oLBwpBAAAABEIQAAACQ3Zw+gMKSlpenChQvy9fWVYRjOHg6KIJvNluF/AaCw8P6D/DJNU7GxsapUqZJcXLI/HlgivlN4/vx5Va1a1dnDAAAAcJpz586pSpUq2c4vEUcKfX19JUmLVm6Ut7ePk0cDoCR6sFVDZw8BQAlls9lUPaSq1UPZKRFRmP6Rsbe3j7x9Sjt5NABKIs4aBeBst/oKHSeaAAAAgCgEAAAAUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAABGFAAAAEFEIAAAAEYUAAAAQUQgAAAARhQAAABBRCAAAAEluzh4AYK+EhHj9fPAn/RZ27MbPiWOyxURLkj5e/LWqhoRmu+4jbe+65fbHTXxf97XrlGn65UsROnJ4v34LO6pfw47pj5NhSrp2TWUCg/TF6i15fh6pqakaNayPTp74RZLUe8BQ9Rn4Qp63A6BoSUtL0+JFi7Rk6Rf6+fBhRUdHy8fHR3Xq1lXXrt304osvydfXN9M6P/74o/bt26v9+/Zp3769On36tCRp9uyP9PzQoU54JiguiEIUWYf379GUN1/O1zb8/APk4pr1AXN3d48sp69avkhfr/wiX/u92bpVS6wgBFAyJCQkqHv3rtryww/WNH9/f9lsNu396Sft/eknzZv7qTZu+kE1atSwlrHZbOrY4QFnDBklAFGIIq1MQKBq1W2oOvUaKqhseX34/qQ8rT99zhIFV6yct50ahipWrqradRuqdr2Girr8p1avWJy3bfzX5UsR+nzebJWvUEnJyUmKjrpi13YAFC1TpkzWlh9+kGEYmvKPf2ro0GHy9/dXcnKyVq9apeHDh+nMmTMaMuRZbdr0Q4Z1fXx8dHeTJmratJmaN2uuV14ZpYiICCc9ExQnRCGKrBb3ttUXbbZav0deDC+U/Q4eNlpDRrxq/b7xu6/t3tbHM95RYmKCXnlrqubMfLcghgegCFi2dIkkacCAgXrttbHWdHd3dz351FO6du2aBg8eqK1btujq1asKCAiQdONo4tVom1xc/vcJxxtvjCvcwaPY4kQTFFmurq5Fer+7d2zRru0/qEWr+3VP6/YFsk0ARUNkZKQkqfHdd2c5v0nTptbjhIQE67FhGBmCEChI/JcFOMG1xAR9PH2qPDw8NXQk/8oHSprq1atLkg4dPJjl/AP790uSgoODVblyHr/iAtiJj49Ror0zYYzCz59RUtI1+ZcJUN36d6rjwz3UotX9Dt3vZ/Nm689LEXpm8Ii8f6cRQJE3+Nnn9OqYV7Rw4QLVql07w3cK16xerdGj/y7DMPTee+87e6goQYrUkcLZs2erevXq8vT0VMuWLfXTTz85e0go4n4NO6q0tDS5ubnpyp+XtHPbZk0cO0JTx7+i69evO2Sfv/96XGtXLVHlqiHq9fRAh+wDwO1t5MiX9cILw2Wapt54fZyCAssoKLCMSvt4qXfvp1S3Xj2tXrNWffr2dfZQUYIUmSOFy5cv16hRo/Txxx+rZcuWmj59ujp37qwTJ06ofPnyzh4eipgHu3RT2wcfUt36d6q0r58k6dyZU/pq6QJt/G6Ntm/9Xj6lffXSmPEFut+0tDTN+r/JSktN1bCRr6tUqVIFun0ARYOrq6v+9cF0hdaooXFjX1NKSopiYmKs+XGxsbr8559OHCFKoiJzpPBf//qXnnvuOQ0cOFANGjTQxx9/LG9vb82fPz/TsklJSbLZbBl+gJuNGjdFTVu0toJQkqqGhOrlsZPU66kBkqTvv12l82dPFeh+v1m9TL+GHVWb9p11d/NWBbptAEVHRESE2rRprTGvjFbv3n104OBhxdjiFHbiN/3jn1P1xx9/6NlnB+n11/nOMQpPkYjC5ORk7d+/Xx06dLCmubi4qEOHDtq1a1em5adOnSp/f3/rp2rVqoU5XBRxvQcMlYeHp0zT1E+7thXYdq9cvqTP5s2Sl7ePnhsxpsC2C6DoGdC/n/b+9JMGDRqs+QsW6q677pKPj49q1aql114bq48+miNJen/aezp27JiTR4uSokhE4eXLl5Wamqrg4OAM04ODg7O8YOe4ceMUExNj/Zw7d66whopiwNPLWyGhtSRJERfOF9h2F30yQwnxcfrb0wPl7V1aiQkJGX5M05QkpVy/bk0DUPz88ssv2rRpoyRp5Mt/z3KZvs88o6CgIKWlpembb9YV5vBQghWZ7xTmhYeHhzw8sr5FGeAslyIvSpI+mzdLn82ble1yK76YpxVfzJMkffvjz4UyNgCFJ+z4cetxaGj292gPrVFDV65c0Zn/3tsYcLQicaSwbNmycnV1tS72mS4yMlIVKlRw0qhQXF1LTNCZUyclicvFAChwN198+uzZs9kud/bMGUlSaV9fh48JkIrIkUJ3d3c1bdpUmzdv1mOPPSbpxlmcmzdv1ogRI5w7OBQ5pmnKMIxs5y9d/ImSkq7JMAw1v6dNge33nRmZT4q62cAnu+hSxAX1HjBUfQa+UGD7BXB7uatRI+vx3Lmf6v33/y/TMuvWrdOlS5ckSS1btCy0saFkKxJRKEmjRo1S//791axZM7Vo0ULTp09XfHy8Bg7kOm8lWUz0VetxXOz/zjKPj7NlmOfr52/963zq+FdUuWqI7m3zoKrXrGNdFub82VNatWyRNny7SpL0YOduqla9ZqZ9pqRcV3xcnPX7tcT/fvfPNDPs08XVVb43nd0MAJJUo0YNdezYSRs3fq+ZM6bL3d1dL7/8d5UvX15xcXH6auVKjRkzWtKNO5907dYtw/oxMTEZrqOalpYmSYpPiNfly5et6b6+vnyVCnlimOnfbi8CZs2apWnTpikiIkKNGzfWzJkz1bLlrf8FZbPZ5O/vry/X75S3T+lCGCkKyyNt78rVcvOXfWd9FDx25CAdObRP0o1w8/EprevXk3UtMdFavnXbjhrz5lSVcnfPtK2fD+7VuJcH33Kf5StU0oLl/87V+CSOFBZ3ne+709lDwG3k4sWL6tTxQR2/6fuFvr6+io2NtX4PDg7WN99+p7v/cn/kBx5op20//njLfcybt0D9BwwosDGj6LLZbAoM8FdMTIz8/LI/WFFkjhRK0ogRI/i4GPn2RN9nVb1GHZ345Wdd/jNSsbExcjFcFFyxsuo1uEsdHuquJs3vdfYwARRjFStW1E979+vTTz/R6tWrdOzoUesv7Fq1aumhhx/RiBEvqly5cs4eKkqQInWk0F4cKQTgbBwpBOAsuT1SWCTOPgYAAIBjEYUAAAAgCgEAAEAUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAEQUAgAAQEQhAAAARBQCAABARCEAAABEFAIAAEBEIQAAAOTgKLx69apiYmIcuQsAAAAUALuj8MKFC1q8eLH+/e9/Z5p37NgxNWvWTGXLllVgYKDatGmjX3/9NV8DBQAAgOPYHYXz58/XwIEDtXXr1gzTExMT9fDDD+vgwYMyTVOmaWrHjh3q0KGDbDZbfscLAAAAB7A7Cjdt2iRJevLJJzNMX7Rokc6dO6fAwEB9+umn+vzzz1WlShWFh4dr9uzZ+RstAAAAHMLuKDx9+rQkqV69ehmmr1q1SoZh6J///KcGDx6s3r1769NPP5Vpmlq7dm2+BgsAAADHsDsKL1++LD8/P3l5eVnT0tLStHPnThmGob/97W/W9I4dO8rFxUUnTpzI32gBAADgEHZHYWpqqpKSkjJMO3LkiBISEtSwYUMFBAT8bycuLgoICFB8fLz9IwUAAIDD2B2FFStWVFJSkk6dOmVN27BhgyTp3nvvzbR8XFycAgMD7d0dAAAAHMjuKGzVqpUkaeLEiUpLS9Off/6pjz76SIZhqHPnzhmWPXXqlJKSklSxYsX8jRYAAAAOYXcUjhw5UpL02WefqUyZMqpatarOnDmj0NBQPfrooxmW3bhxoySpSZMm+RgqAAAAHMXuKGzRooXmz5+v0qVLKy4uTsnJyapXr55WrVolNze3DMsuXrxYktS+ffv8jRYAAAAOYZimaeZnA4mJiTp69KjKlCmjmjVrysUlY2cmJydr2bJlMk1T3bt3V5kyZfKzO7vYbDb5+/vry/U75e1TutD3DwCd77vT2UMAUELZbDYFBvgrJiZGfn5+2S7nlu2cXPLy8lLz5s2zne/u7q5+/frldzcAAABwILs/PgYAAEDxQRQCAAAgdx8f16hRo0B2ZhiGfv/99wLZFgAAAApOrqIw/T7H+WUYRoFsBwAAAAUrV1G4YMECR48DAAAATpSrKOzfv7+jxwEAAAAn4kQTAAAAEIUAAAAgCgEAAKACiMLDhw9ryJAhatCggfz8/OTq6prtz1/viQwAAIDbQ74qbdasWRo1apRSU1OVz1soAwAAwInsPlK4Z88ejRw5UqmpqXrhhRe0fv16SVJgYKA2bdqkzz//XAMGDJC7u7vKli2rJUuW6IcffiiwgQMAAKDg2H2kcObMmTJNUy+//LL+9a9/WdPd3d31wAMPSJJ69+6tl156SZ07d9Zbb72lAwcO5H/EAAAAKHB2HyncsWOHDMPQyJEjM0z/68fIjRs31ocffqjff/9d06ZNs3d3AAAAcCC7ozAyMlIeHh4KCQn538ZcXHTt2rVMy/bo0UOlSpXSqlWr7N0dAAAAHMjuj4+9vb0z3cvY19dXNptNSUlJ8vDwsKaXKlVK3t7eOnPmjP0jBQAAgMPYfaSwcuXKstlsSklJsabVrFlTkrR3794My164cEExMTGcoQwAAHCbsjsK69evr9TUVB05csSa1q5dO5mmqUmTJlkfIycnJ+ull16SJN155535HC4AAAAcwe4o7NSpk0zT1Lp166xpw4cPl4eHhzZv3qwqVaqodevWqly5slavXi3DMDRixIgCGTQAAAAKlt3fKezVq5fOnz+vSpUqWdNCQ0O1ZMkSDRw4UFFRUdq1a5ekGyegjBkzRn369Mn/iAEAAFDgDNMBX/SLiorS+vXrde7cOfn7+6tTp06qVatWQe8m12w2m/z9/fXl+p3y9inttHEAKLk638fXZwA4h81mU2CAv2JiYuTn55ftcg65GXFgYKD69u3riE0DAADAAez+TiEAAACKD6IQAAAA9n98nH5/47wwDEObN2+2d5cAAABwELujcOvWrblaLv2uJ6ZpZroDCgAAAG4Pdkfh+PHjc5wfExOjPXv2aNeuXQoKCtKwYcPk6upq7+4AAADgQA6LwnQ//PCDevbsqV9++UUrV660d3cAAABwIIefaPLAAw9oxowZWr16tebOnevo3QEAAMAODrl49V9du3ZNfn5+atKkiXbv3u3o3WWSfvHqyMtXc7xoIwAAQHFjs9kUXDbglhevLpRL0nh6esrHx0fHjx8vjN0BAAAgjwolCsPDwxUTE6NCOCgJAAAAOzg8ChMTE/XCCy9Iku68k3t/AgAA3I7sPvt40qRJOc6/du2azp07pw0bNujKlSsyDEPDhw+3d3cAAABwILujcMKECbm6GLVpmnJxcdGbb76p3r1727s7AAAAOJDdUXj//ffnGIVubm4KCAhQo0aN9MQTT6h27dr27goAAAAO5vDb3AEAAOD2VyhnHwMAAOD2ZncUTpo0Sf/6179yvfzMmTNveXIKAAAAnMPuO5q4uLioQoUKunDhQq6WDw0N1dmzZ5WammrP7vKFO5oAAICS6ra6owkAAABub4UWhVFRUfL09Cys3QEAACAPCiUKv/zyS8XGxqpatWqFsTsAAADkUa4vSTNjxgzNmDEjw7Q///xTNWrUyHYd0zQVHR0tm80mwzD0yCOP2D9SAAAAOEyuozA6OlqnT5/OMC01NTXTtOw8+OCDevvtt/MyNgAAABSSXEfhY489purVq0u6cQRw0KBB8vf31/Tp07Ndx8XFRX5+frrjjjtUs2bN/I4VAAAADlJol6RxJi5JAwAASqrcXpLG7tvcpaWl2bsqAAAAbjNcpxAAAAD2R+Hu3bvVpEkTDR8+/JbLPvvss2rSpIn27dtn7+4AAADgQHZH4ZIlS3T48GG1adPmlsvec889OnTokJYsWWLv7gAAAOBAdkfhjz/+KEnq1KnTLZft0aOHJGnLli327g4AAAAOZHcUnj9/Xv7+/goMDLzlskFBQfL391d4eLi9uwMAAIAD2R2FiYmJeToD2TRNxcbG2rs7AAAAOJDdUVi+fHnFxsbm6jqF4eHhstlsKlu2rL27AwAAgAPZHYX33HOPJGn27Nm3XDZ9mZYtW9q7OwAAADiQ3VE4ePBgmaap9957T5988km2y82ZM0fvvfeeDMPQ4MGD7d0dAAAAHMju29xJ0hNPPKGVK1fKMAzdcccdevTRRxUSEiJJOnPmjNatW6djx47JNE316tVLX375ZYENPC+4zR0AACipHH6bO0latGiRDMPQl19+qSNHjujo0aMZ5qf35lNPPaV58+blZ1cAAABwoHzd5s7Ly0vLly/Xpk2b1Lt3b4WEhMjDw0Oenp6qXr26+vTpox9++EFLliyRl5dXQY0ZAAAABSxfHx/nVlpamr799lvNmzdPa9ascfTuMuHjYwAAUFIVysfHt/Lbb79p3rx5Wrx4sSIjIx25KwAAAORDgUdhQkKCVqxYoXnz5mnnzp2S/vfdwvr16xf07gAAAFAACiwKd+/erXnz5mnFihWKi4uTdCMG69Wrp8cff1yPP/647rjjjoLaHQAAAApQvqLwzz//1OLFizV//nyFhYVJ+t9RQcMwtHfvXjVt2jT/owQAAIBD5TkKTdPU+vXrNX/+fH3zzTdKSUmRaZry8vLSY489pv79+6tLly6S+LgYAACgqMh1FP7++++aP3++Fi1apIsXL8o0TRmGofvuu0/9+vXTE088IV9fX0eOFQAAAA6S6yisXbu2DMOQaZoKDQ1Vv3791K9fP4WGhjpyfAAAACgEef74+KWXXtJ7770nd3d3R4wHAAAATpDrO5p4eHjINE19+OGHqlSpkoYPH67du3c7cmwAAAAoJLmOwosXL2rmzJm66667FBUVpY8++kitW7dW3bp19c9//lNnz5515DgBAADgQHbd5u7gwYOaO3euli5dqujoaBmGIcMwdP/99+uZZ57R4MGDZRiGYmNj5e3t7Yhx5wm3uQMAACVVbm9zl697HyclJWnlypWaN2+efvzxR+uM5PT//eqrr/Too4/Kzc2hd9O7JaIQAACUVLmNwlx/fJwVDw8P9enTRz/88INOnjypN954Q5UrV5Z043qGvXr1Uvny5TVw4ECtX79eKSkp+dkdAAAAHCRfRwqzYpqmNmzYoLlz52rdunW6fv26DMOQJJUpU0ZXrlwpyN3lCkcKAQBASVUoRwqzYhiGunTpopUrVyo8PFzvv/++6tevL9M0FR0dXdC7AwAAQAEo8Ci8WdmyZTVq1CgdPXpUO3fu1ODBgx25OwAAANip0M4Aueeee3TPPfcU1u4AAACQBw49UggAAICigSgEAAAAUQgAAACiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiClFMnT17Vh/OnKFej3VT7ZrV5V/aS+UC/dWi6d168/VxunjxYo7rJycn6//en6aWzZqobICfKpQLVNs2rTVv7icyTTPb9U7+9psWLZyvkS8OV+tWLeVf2kte7q66/757C/opAriNOes9KCtrv14jL3dX6wfIjmHm9b+uIshms8nf31+Rl6/Kz8/P2cOBg507d051a4VmeOP08/NTfHy8UlNTJUkBAQFauvxLtW3XPtP6NptND3XqoAMH9kuSvL29lZKSouTkZEnSww8/ouUrV8nNzS3Tuo/36qFv1q3NNL15i5batn1ngTw/ALc3Z74H/VVcXJwa39VQ4efPW9MSk1Pz9fxQ9NhsNgWXDVBMTEyOHcSRQhQ7af99033o4Yf1xdLluhB5WZGXryoqJk5r1n6j6qGhunr1qp74W09FRERkWv+FoUN04MB+BQYG6qvVX+vyVZuiYuL06dz58vT01Pr132ryxAlZ7tvV1VX16tVXn77P6P8+mKHeffo68qkCuA058z3oryZOeFvh58+reYuWBfkUUUxxpBDFTkxMjM6cPq27GjXKcv6JsDDd06Kprl27pjffGq833nrbmnfo4EG1atlMkvTlV6v1aNduGdad9eFMjRn9d3l5eSnstz9Uvnz5DPNTU1Pl6vq/j2emTJqof0yZxJFCoARx5nvQzQ4ePKA2996jRo0aa8jQoRo65DlJHCksiThSiBLL398/2zdjSapbr55atLxHknTwvx/PpFu+fKkkqU6dupnejCVp8LPPyd/fX4mJifp6zapM828OQgAlkzPfg9KlpaVpxAvDZJqmZsyaLRcX/rrHrfFfCUqkwMBASVJqWsZ/MW/bulWS9GDHjlmu5+Xlpdat75Mkbd2yxXEDBFCsOfo96KP/N1sH9u/T4GefU7NmzQtgxCgJiEKUOCkpKdq968ZHuQ0a3GFNN01TJ06E/Xd6g2zXr1f/xryw48cdOEoAxZWj34PCw8M1cfxbKleunCZO/kdBDRslQJGIwm3btqlr166qVKmSDMPQmjVrnD0kFGEff/T/FBERIRcXF/V9pp813WazKT4+XpJUsWKlbNevWOnGvIiInC8pAQBZcfR70KiXX1JsbKz+MfUdBQQEFODIUdwViSiMj49Xo0aNNHv2bGcPBUXckZ9/1ttvvi5JGvrCcNW/6V/j6W/G0o2PaLLj7X1jXlxcnINGCaC4cvR70LffrNPar9fo3tb3qe8z/Qtq2Cghbn2Ro9vAQw89pIceeijXyyclJSkpKcn63WazOWJYKGIuXryoJx7vqcTERDVp0lT/+Oc7zh4SgBLE0e9B8fHx+vvLL8nNzU0zZs6SYRgFun0Uf0XiSGFeTZ06Vf7+/tZP1apVnT0kOFlUVJS6PtxFp0+dUq1atbXq63Xy9PTMsIyPj4/1ODExMdttJSTcmFe6dGnHDBZAsVMY70GTJo7XubNn9cKIF3XHnXcW4OhRUhTLKBw3bpxiYmKsn3Pnzjl7SHCimJgYdX3kIR07dlRVq1XTt//+XsHBwZmW8/Pzs96UL168kO32Ll64Ma9ChYqOGTCAYqUw3oN+P3lSsz+cqfLly+vlv49WXFxchp+bPz1Ln5Z+hxQgXZH4+DivPDw85OHh4exh4DYQHx+vx7o9qgP796lChQpa/933qlatWpbLGoahuvXq68D+ffrll1+y3WbY8Rvz6tWv75AxAyg+Cus9KDz8vFJTU3Xp0iXVCKmS45jKBfpLkt548229+fb4vD4lFGPF8kghIN34+KVXj+7avWungoKC9O1336tW7do5rtO2bTtJ0g+bNmU5/9q1a9qxY7skqf0DDxToeAEUL7wHoaghClEsJScn66kneunHrVtUpkwZrVv/bzVo2PCW6z3x5FOSpBMnwrT+228yzZ8/b65iYmLk5eWlbt17FPi4ARQPhf0edH/bdkpMTs3255O586xl06dxlBB/VSSiMC4uTocOHdKhQ4ckSadOndKhQ4d09uxZ5w4Mt6XU1FT1f6aPvt+wQb6+vlqz7lvdfXeTXK3b+O671etvj0uShjw7SP/+br21zS8+W6w3Xx8rSXrxpZezvOdoUlKSLl++bP0kJCTcWD8lJcP0mJiYgniqAG5DznwPAvLDME3TdPYgbmXr1q1q3759pun9+/fXwoULb7m+zWaTv7+/Ii9fzfFG0Cgetv9nmzo+eOO/F09PT/n7+2e7bOUqVbVj154M02w2mx7q1EEH/ntPUm9vb6Wmplpf1H744Ue0fOUqubll/kruZ4sXasizg285xjb3t9X3m37I9XMCUHQ48z0oOze/NyUmp95iaRQ3NptNwWUDFBMTk2MHFYkTTdq1a6ci0K64TaSlpVmPr127pmvXrmW7rMdfLgkh3TgDcMu27Zo5Y7q+XL5Mv/9+Uh4eHmrU+G71699fgwY/x/W/AGSL9yAUVUXiSGF+caQQAACUVLk9UlgkvlMIAAAAxyIKAQAAQBQCAACAKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAACIKAQAAICIQgAAAIgoBAAAgIhCAAAAiCgEAACAiEIAAABIcnP2AAqDaZqSpNhYm5NHAgAAULjS+ye9h7JTIqIwNjZWklQrNMTJIwEAAHCO2NhY+fv7ZzvfMG+VjcVAWlqaLly4IF9fXxmG4ezhoAiy2WyqWrWqzp07Jz8/P2cPB0AJwvsP8ss0TcXGxqpSpUpyccn+m4Ml4kihi4uLqlSp4uxhoBjw8/PjTRmAU/D+g/zI6QhhOk40AQAAAFEIAAAAohDIFQ8PD40fP14eHh7OHgqAEob3HxSWEnGiCQAAAHLGkUIAAAAQhQAAACAKAQAAIKIQAAAAIgoBIEft2rWTYRiaMGFCpnnVq1eXYRhauHBhoY5p4cKFMgxD1atXL9T9AijeiEIADjVhwgQZhpHpx9PTU1WqVFG3bt20YsWKW96ovSQ4ffq0JkyYkGWAAoCjlYjb3AG4PQQHB1uPY2JiFB4ervDwcK1bt04LFy7U6tWri9S12GrWrClPT89c3T4qN06fPq2JEydKUo5h6O/vr7p166py5coFsl8AkDhSCKAQRUREWD/x8fE6evSoOnbsKEn67rvv9Oabbzp5hHmzefNmhYWFqUePHoW63x49eigsLEybN28u1P0CKN6IQgBO4eLiooYNG2rt2rWqVauWJGnOnDlKSUlx8sgAoGQiCgE4laenpx5//HFJUmxsrMLCwnT69Gnru4enT5/W77//riFDhig0NFQeHh6ZTrBIS0vTF198oYcffljBwcFyd3dXuXLl1KlTJy1dujTH7yumpqbqww8/VJMmTeTj46PAwEC1a9dOK1euvOXYc3OiyZ49ezRw4EDVqlVL3t7e8vPzU4MGDTRo0CBt2LAhw7bat29v/f7X72AOGDDAmpebE01+//13DRs2TLVr15aXl5f8/PzUpEkTTZo0STabLct1tm7dau1Pkk6ePKlBgwapatWq8vDwUJUqVfTcc88pPDw82/2GhYVpyJAhqlOnjry9veXp6amqVavqnnvu0euvv66wsLBs1wXgXHynEIDTValSxXpss9lUunRp6/edO3fq+eefV1xcnLy9vVWqVKkM60ZFRalHjx7atm2bNc3f31+XL1/Wxo0btXHjRi1btkxffvml3N3dM6yblJSk7t27W3Hm4uIid3d3bdu2TT/++KNee+01u59TamqqRo0apZkzZ1rTfHx85ObmprCwMB0/flyrVq1SdHS0JKlcuXKy2Wy6evWqpIzfv0x/Trm1YsUK9evXT0lJSZIkX19fJScn6+DBgzp48KDmzp2rDRs2qH79+tluY8uWLerWrZvi4uLk6+urtLQ0hYeHa+7cuVq/fr1++umnTN9p3Lhxo7p27Wrtt1SpUvLx8dH58+d1/vx57dmzR+7u7pxIA9ymOFIIwOlOnz5tPQ4MDMww7/nnn1fDhg21d+9excfHKy4uTt9//72kG+HVs2dPbdu2TY0bN9a6desUHx+v6OhoxcXFadGiRSpfvrzWrl2bZeCNGzdOGzZskGEYmjJliq5evaqrV68qIiJCw4YN07vvvqtDhw7Z9Zxef/11KwgHDRqkEydOKC4uTlFRUbp69arWrFmjLl26WMvv3btXq1atsn6/+fuXERERmjFjRq72e+DAAfXt21dJSUlq3bq1fv75Z9lsNiUkJGjt2rWqWLGizp07p65duyouLi7b7fTq1UsPPPCAjh8/LpvNpvj4eC1fvly+vr66cOGCxo0bl2mdYcOGKSkpSZ06ddKRI0eUnJysq1evKjExUUePHtXEiRO5jA5wOzMBwIHGjx9vSjKze7uJiYkxK1WqZEoyAwMDzdTUVPPUqVPWOiEhIWZsbGyW6y5evNiUZNarV8+Mjo7Ocpl9+/aZhmGY7u7uZmRkpDU9PDzcdHNzMyWZb731VpbrPv3009Y4xo8fn2l+SEiIKclcsGBBhuknTpwwXVxcTEnmq6++muW2s7Jly5YcX6t0CxYssF6bv+rSpYspyaxVq5YZHx+faf6BAwes5z1t2rRs99++fXszNTU10/ozZ840JZleXl7m9evXremRkZHWuhcuXMjlMwZwO+FIIQCniI6O1ubNm/XAAw/owoULkqSRI0fKxSXj29KIESMyfJx8s3nz5km6cYQqu49XmzZtqoYNGyo5OVlbtmyxpq9cuVIpKSny8vLSK6+8kuW69n7MuWjRIqWlpSkoKMi6xExhiI6Otj4KHzNmjLy9vTMtc/fdd6tnz56SpKVLl2a7rddffz3Tn4Ukde/eXZKUmJio3377zZru6+trLX/x4kX7nwQApyEKARSam0+cCAgIUIcOHbR//35JUt++ffXGG29kWqd169ZZbis1NVW7d++WdCPeKlSokO3PiRMnJElnzpyx1t+3b58kqVmzZvLz88tyH3Xq1LHrWoA7d+6UJHXs2FGenp55Xt9eBw4csE6q6dChQ7bLpV8G6Oeff9b169ezXKZly5ZZTq9UqZL1OCoqynrs5eWlBx98UJLUpUsXvf3229qzZ4+Sk5Pz9iQAOA0nmgAoNDefPOHh4aGyZcvq7rvvVp8+fTKceXuz8uXLZzk9KirKOqEh/eSMW0lISLAeX7p0SZJuGX1VqlTJ8WzbrEREREiSQkJC8rRefqU/Jynn55V+Yk9KSoqioqIyndQi3TjylxU3t//9tfHXoJw7d666deumw4cPa/LkyZo8ebLc3d3VvHlzde/eXYMHD870nVEAtw+iEEChSY+lvHB1dc1yempqqvX4u+++y3DShrOlX9KlpKlWrZoOHDigjRs3av369dqxY4cOHz6sHTt2aMeOHZo6dapWrlypBx54wNlDBZAFPj4GUCQFBQVZR61u/lg4t9KPQN7qKGBejxJKUoUKFeweV37cfFT1/Pnz2S6XPs/Nza3Aj9y5uLioc+fOmjFjhvbt26eoqCh98cUXqlatmq5evarevXvzkTJwmyIKARRJpUqVUosWLSRJ69aty/P6zZo1k3Tju4XZXZrlt99+yzGusnPvvfdKunHdvmvXruV6vZtP7DBzuOB2dpo0aWJtI6db4G3atEmS1KhRo0zXfSxovr6+6t27t3VSUGRkpI4cOeLQfQKwD1EIoMgaMmSIJGn9+vVav359jsvefFKEdOM6fK6urkpMTNT777+f5TqTJk2ya1wDBgyQq6urrly5ovHjx+d6vZtPeEm/qHVelClTRp07d5YkTZs2LcN3KNMdPnxYX331lSTp6aefzvM+snOro39eXl7W46zOagbgfPw/E0CR1bdvX3Xo0EGmaapHjx6aMmWKdXkbSYqPj9eWLVs0fPhw1ahRI8O6lStX1vDhwyVJkydP1tSpUxUbGytJ+vPPPzVixAh9/vnnebqTSLpatWppzJgxkqT33ntPzz77bIbLt9hsNi1fvlw9evTIsF6dOnWsu67MnTvXrqOFU6ZMUalSpXTy5El17tzZOiqXlpam9evX6+GHH1ZKSopq1qyp559/Ps/bz87OnTt111136YMPPtDx48eVlpYm6cYRz507d2rYsGGSbpzkctdddxXYfgEUIKdeJRFAsXeri1dn5eaLV586dSrHZWNiYsxHH33UWl6S6efnZ5YpU8Y0DMOa5ubmlmndxMREs0OHDtYyrq6uZkBAgLXea6+9ZrZt2zbPF682TdNMSUkxhw8fnmFcpUuXzrB9f3//TOsNHjzYWt7b29usVq2aGRISYo4ePdpaJqeLV5umaS5btsx0d3fP8Hp4enpav1etWtX85ZdfMq2X24tnpy+zZcuWLNeVZJYqVcoMCgqyLpSdPo5t27bluG0AzsORQgBFmp+fn9atW6f169frySefVLVq1ZSUlKSEhARVrlxZnTp10tSpU61rFd7M09NT3333nWbMmKHGjRvL3d1dpmmqTZs2WrFihd555x27x+Xq6qpZs2Zp+/bt6tOnj6pVq6br16/LNE01aNBAgwcPtj7Gvdns2bM1YcIE3XnnnZKks2fP6syZM7p8+XKu9/3kk0/q2LFjev7551WzZk0lJSXJzc1NjRs31sSJE3X06NEc73tsj+bNm2vFihUaNmyYmjZtqrJly8pms8nT01ONGzfWq6++quPHj6tNmzYFul8ABccwTTs+nwAAAECxwpFCAAAAEIUAAAAgCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAgohAAAAAiCgEAACCiEAAAACIKAQAAIKIQAAAAIgoBAAAg6f8Dta5x245PxAYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 750x750 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework**\n",
    "- Use the dataset: https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset.\n",
    "- Experiment with the number of hidden layers, and the number of units in the hidden layer.\n",
    "- Try to experiment on the activation functions in the hidden layer https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
    "- Try to experiment with the optimizer: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "- Check the accuracy, specificity, and sensitivity of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
