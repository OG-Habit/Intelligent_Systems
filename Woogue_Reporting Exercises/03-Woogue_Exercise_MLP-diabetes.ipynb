{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Ivan\\Desktop\\School\\4th year - 1st sem\\4103 intelligent systems\\final\\Forked from Gerard repo\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('03-diabetes_prediction_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0             0              1           never  25.19   \n",
       "1      Female  54.0             0              0         No Info  27.32   \n",
       "2        Male  28.0             0              0           never  27.32   \n",
       "3      Female  36.0             0              0         current  23.45   \n",
       "4        Male  76.0             1              1         current  20.14   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "99995  Female  80.0             0              0         No Info  27.32   \n",
       "99996  Female   2.0             0              0         No Info  17.37   \n",
       "99997    Male  66.0             0              0          former  27.83   \n",
       "99998  Female  24.0             0              0           never  35.42   \n",
       "99999  Female  57.0             0              0         current  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "0              6.6                  140         0  \n",
       "1              6.6                   80         0  \n",
       "2              5.7                  158         0  \n",
       "3              5.0                  155         0  \n",
       "4              4.8                  155         0  \n",
       "...            ...                  ...       ...  \n",
       "99995          6.2                   90         0  \n",
       "99996          6.5                  100         0  \n",
       "99997          5.7                  155         0  \n",
       "99998          4.0                  100         0  \n",
       "99999          6.6                   90         0  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age hypertension heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0            0             1           never  25.19   \n",
       "1      Female  54.0            0             0         No Info  27.32   \n",
       "2        Male  28.0            0             0           never  27.32   \n",
       "3      Female  36.0            0             0         current  23.45   \n",
       "4        Male  76.0            1             1         current  20.14   \n",
       "...       ...   ...          ...           ...             ...    ...   \n",
       "99995  Female  80.0            0             0         No Info  27.32   \n",
       "99996  Female   2.0            0             0         No Info  17.37   \n",
       "99997    Male  66.0            0             0          former  27.83   \n",
       "99998  Female  24.0            0             0           never  35.42   \n",
       "99999  Female  57.0            0             0         current  22.43   \n",
       "\n",
       "      HbA1c_level blood_glucose_level  \n",
       "0             6.6                 140  \n",
       "1             6.6                  80  \n",
       "2             5.7                 158  \n",
       "3             5.0                 155  \n",
       "4             4.8                 155  \n",
       "...           ...                 ...  \n",
       "99995         6.2                  90  \n",
       "99996         6.5                 100  \n",
       "99997         5.7                 155  \n",
       "99998         4.0                 100  \n",
       "99999         6.6                  90  \n",
       "\n",
       "[100000 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X, columns = [\"gender\",\"age\",\"hypertension\",\"heart_disease\",\"smoking_history\",\"bmi\",\"HbA1c_level\",\"blood_glucose_level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       diabetes\n",
       "0             0\n",
       "1             0\n",
       "2             0\n",
       "3             0\n",
       "4             0\n",
       "...         ...\n",
       "99995         0\n",
       "99996         0\n",
       "99997         0\n",
       "99998         0\n",
       "99999         0\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y, columns = [\"diabetes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "VYP9cQTWbzuI",
    "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Female', 80.0, 0, ..., 25.19, 6.6, 140],\n",
       "       ['Female', 54.0, 0, ..., 27.32, 6.6, 80],\n",
       "       ['Male', 28.0, 0, ..., 27.32, 5.7, 158],\n",
       "       ...,\n",
       "       ['Male', 66.0, 0, ..., 27.83, 5.7, 155],\n",
       "       ['Female', 24.0, 0, ..., 35.42, 4.0, 100],\n",
       "       ['Female', 57.0, 0, ..., 22.43, 6.6, 90]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "38vKGE6Nb2RR",
    "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6bQ0UgSU-NJ"
   },
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le5MJreAbW52"
   },
   "source": [
    "Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxVKWXxLbczC"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 0] = le.fit_transform(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "-M1KboxFb6OO",
    "outputId": "e2b8c7e8-0cbc-4cdf-f4eb-7f0853a00b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 80.0 0 ... 25.19 6.6 140]\n",
      " [0 54.0 0 ... 27.32 6.6 80]\n",
      " [1 28.0 0 ... 27.32 5.7 158]\n",
      " ...\n",
      " [1 66.0 0 ... 27.83 5.7 155]\n",
      " [0 24.0 0 ... 35.42 4.0 100]\n",
      " [0 57.0 0 ... 22.43 6.6 90]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0, 80.0, 0, 1, 25.19, 6.6, 140],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUxGZezpbMcb"
   },
   "source": [
    "One Hot Encoding the \"smoking_history\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMXC8-KMVirw"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [4])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "ZcxwEon-b8nV",
    "outputId": "23a98af4-5e33-4b26-c27b-f06e3c5d2baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 0.0 ... 25.19 6.6 140]\n",
      " [1.0 0.0 0.0 ... 27.32 6.6 80]\n",
      " [0.0 0.0 0.0 ... 27.32 5.7 158]\n",
      " ...\n",
      " [0.0 0.0 0.0 ... 27.83 5.7 155]\n",
      " [0.0 0.0 0.0 ... 35.42 4.0 100]\n",
      " [0.0 1.0 0.0 ... 22.43 6.6 90]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Ivan\\Desktop\\School\\4th year - 1st sem\\4103 intelligent systems\\final\\Forked from Gerard repo\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the third hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the fourth hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "# ann.add(tf.keras.layers.Dense(units=1, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Ivan\\Desktop\\School\\4th year - 1st sem\\4103 intelligent systems\\final\\Forked from Gerard repo\\venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# layers\n",
    "# 6 units relu\n",
    "# 6 units relu\n",
    "# output layer sigmoid\n",
    "\n",
    "# ann.compile(optimizer = 'adadelta', loss = 'binary_crossentropy', metrics = ['accuracy'])     # stayed pretty much the same at 91.5\n",
    "# ann.compile(optimizer = 'adafactor', loss = 'binary_crossentropy', metrics = ['accuracy'])    # experimental\n",
    "# ann.compile(optimizer = 'adagrad', loss = 'binary_crossentropy', metrics = ['accuracy'])      # 92.21 - 95.53\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])         # 95.85 - 96.61\n",
    "# ann.compile(optimizer = 'adamw', loss = 'binary_crossentropy', metrics = ['accuracy'])        # error\n",
    "# ann.compile(optimizer = 'ftrl', loss = 'binary_crossentropy', metrics = ['accuracy'])         # stuck at 91.50 at all times\n",
    "# ann.compile(optimizer = 'lion', loss = 'binary_crossentropy', metrics = ['accuracy'])         # error\n",
    "# ann.compile(optimizer = 'nadam', loss = 'binary_crossentropy', metrics = ['accuracy'])        # 95.24 - 96.04 2nd epoch to the end basically just stayed the same\n",
    "# ann.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])      # 96.04 stayed the same from 1st to last epoch\n",
    "# ann.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])          # 95.67 - 96.03 was very stagnant starting from epoch 19\n",
    "\n",
    "# adam seems to be the best performing optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/2500 [..............................] - ETA: 20s - loss: 0.0652 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1055 - accuracy: 0.9614\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1052 - accuracy: 0.9614\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1050 - accuracy: 0.9616\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1049 - accuracy: 0.9614\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1047 - accuracy: 0.9614\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1044 - accuracy: 0.9619\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1042 - accuracy: 0.9618\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1040 - accuracy: 0.9619\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1038 - accuracy: 0.9622\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1037 - accuracy: 0.9619\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1033 - accuracy: 0.9618\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1029 - accuracy: 0.9625\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1027 - accuracy: 0.9628\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1023 - accuracy: 0.9628\n",
      "Epoch 15/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1018 - accuracy: 0.9635\n",
      "Epoch 16/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1011 - accuracy: 0.9637\n",
      "Epoch 17/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1004 - accuracy: 0.9643\n",
      "Epoch 18/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0995 - accuracy: 0.9649\n",
      "Epoch 19/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0986 - accuracy: 0.9655\n",
      "Epoch 20/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0976 - accuracy: 0.9663\n",
      "Epoch 21/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0969 - accuracy: 0.9670\n",
      "Epoch 22/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0962 - accuracy: 0.9670\n",
      "Epoch 23/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0956 - accuracy: 0.9676\n",
      "Epoch 24/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0952 - accuracy: 0.9678\n",
      "Epoch 25/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0947 - accuracy: 0.9681\n",
      "Epoch 26/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0943 - accuracy: 0.9683\n",
      "Epoch 27/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0940 - accuracy: 0.9685\n",
      "Epoch 28/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0937 - accuracy: 0.9688\n",
      "Epoch 29/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0934 - accuracy: 0.9689\n",
      "Epoch 30/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0931 - accuracy: 0.9690\n",
      "Epoch 31/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0927 - accuracy: 0.9691\n",
      "Epoch 32/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0925 - accuracy: 0.9693\n",
      "Epoch 33/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0921 - accuracy: 0.9693\n",
      "Epoch 34/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0919 - accuracy: 0.9696\n",
      "Epoch 35/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0915 - accuracy: 0.9696\n",
      "Epoch 36/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0911 - accuracy: 0.9699\n",
      "Epoch 37/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0909 - accuracy: 0.9696\n",
      "Epoch 38/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0906 - accuracy: 0.9697\n",
      "Epoch 39/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0902 - accuracy: 0.9702\n",
      "Epoch 40/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0900 - accuracy: 0.9702\n",
      "Epoch 41/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0896 - accuracy: 0.9702\n",
      "Epoch 42/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0893 - accuracy: 0.9702\n",
      "Epoch 43/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0890 - accuracy: 0.9705\n",
      "Epoch 44/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0887 - accuracy: 0.9704\n",
      "Epoch 45/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0882 - accuracy: 0.9704\n",
      "Epoch 46/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0880 - accuracy: 0.9707\n",
      "Epoch 47/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0878 - accuracy: 0.9704\n",
      "Epoch 48/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0874 - accuracy: 0.9706\n",
      "Epoch 49/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0872 - accuracy: 0.9709\n",
      "Epoch 50/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0869 - accuracy: 0.9708\n",
      "Epoch 51/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0866 - accuracy: 0.9709\n",
      "Epoch 52/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0865 - accuracy: 0.9707\n",
      "Epoch 53/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0863 - accuracy: 0.9708\n",
      "Epoch 54/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0860 - accuracy: 0.9710\n",
      "Epoch 55/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0858 - accuracy: 0.9709\n",
      "Epoch 56/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0857 - accuracy: 0.9711\n",
      "Epoch 57/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0855 - accuracy: 0.9709\n",
      "Epoch 58/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0854 - accuracy: 0.9709\n",
      "Epoch 59/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0852 - accuracy: 0.9710\n",
      "Epoch 60/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0852 - accuracy: 0.9712\n",
      "Epoch 61/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0850 - accuracy: 0.9712\n",
      "Epoch 62/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0849 - accuracy: 0.9712\n",
      "Epoch 63/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0848 - accuracy: 0.9711\n",
      "Epoch 64/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0847 - accuracy: 0.9711\n",
      "Epoch 65/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0846 - accuracy: 0.9712\n",
      "Epoch 66/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0845 - accuracy: 0.9711\n",
      "Epoch 67/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0844 - accuracy: 0.9712\n",
      "Epoch 68/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0844 - accuracy: 0.9712\n",
      "Epoch 69/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0843 - accuracy: 0.9713\n",
      "Epoch 70/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0843 - accuracy: 0.9713\n",
      "Epoch 71/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0842 - accuracy: 0.9713\n",
      "Epoch 72/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0841 - accuracy: 0.9713\n",
      "Epoch 73/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0841 - accuracy: 0.9714\n",
      "Epoch 74/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0841 - accuracy: 0.9712\n",
      "Epoch 75/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0840 - accuracy: 0.9713\n",
      "Epoch 76/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0840 - accuracy: 0.9714\n",
      "Epoch 77/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0839 - accuracy: 0.9713\n",
      "Epoch 78/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0838 - accuracy: 0.9714\n",
      "Epoch 79/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0839 - accuracy: 0.9713\n",
      "Epoch 80/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0838 - accuracy: 0.9714\n",
      "Epoch 81/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0838 - accuracy: 0.9712\n",
      "Epoch 82/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0838 - accuracy: 0.9715\n",
      "Epoch 83/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0837 - accuracy: 0.9714\n",
      "Epoch 84/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0837 - accuracy: 0.9714\n",
      "Epoch 85/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0836 - accuracy: 0.9714\n",
      "Epoch 86/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0837 - accuracy: 0.9713\n",
      "Epoch 87/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0836 - accuracy: 0.9713\n",
      "Epoch 88/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0835 - accuracy: 0.9713\n",
      "Epoch 89/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0836 - accuracy: 0.9715\n",
      "Epoch 90/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0835 - accuracy: 0.9715\n",
      "Epoch 91/100\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0835 - accuracy: 0.9713\n",
      "Epoch 92/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0835 - accuracy: 0.9715\n",
      "Epoch 93/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0835 - accuracy: 0.9713\n",
      "Epoch 94/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0835 - accuracy: 0.9715\n",
      "Epoch 95/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0834 - accuracy: 0.9714\n",
      "Epoch 96/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0834 - accuracy: 0.9714\n",
      "Epoch 97/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0834 - accuracy: 0.9715\n",
      "Epoch 98/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0834 - accuracy: 0.9714\n",
      "Epoch 99/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0833 - accuracy: 0.9715\n",
      "Epoch 100/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0834 - accuracy: 0.9715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bb77071290>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.adam.Adam at 0x1bb735c8050>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Part 4 - Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ci6K_r6LaF6P",
    "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18284    13]\n",
      " [  554  1149]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97165"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x750 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ann.compile(optimizer = 'adadelta', loss = 'binary_crossentropy', metrics = ['accuracy'])     0 true positives, 0 false positive, 18297 on true negatives\n",
    "ann.compile(optimizer = 'adafactor', loss = 'binary_crossentropy', metrics = ['accuracy'])    experimental\n",
    "ann.compile(optimizer = 'adagrad', loss = 'binary_crossentropy', metrics = ['accuracy'])      92.21 - 95.53\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])         95.85 - 96.61\n",
    "ann.compile(optimizer = 'adamw', loss = 'binary_crossentropy', metrics = ['accuracy'])        error\n",
    "ann.compile(optimizer = 'ftrl', loss = 'binary_crossentropy', metrics = ['accuracy'])         0 true positives, 0 false positive, good true negative\n",
    "ann.compile(optimizer = 'lion', loss = 'binary_crossentropy', metrics = ['accuracy'])         error\n",
    "ann.compile(optimizer = 'nadam', loss = 'binary_crossentropy', metrics = ['accuracy'])        581 false negative, 198 false positive\n",
    "ann.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])      517 false negative, 371 false positive, 1186 true positive\n",
    "ann.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])          505 false negative, 382 false positive, 1198 true positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (32, 6)                   84        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (32, 6)                   42        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (32, 1)                   7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133 (532.00 Byte)\n",
      "Trainable params: 133 (532.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using adam optimizer\n",
    "1. 3 layers - all relu\n",
    "    - 0.97245\n",
    "    - 0 false positives, 1152 true positive, 551 false negative\n",
    "2. 3 layers - all sigmoid\n",
    "    - 0.9702\n",
    "    - 1149 true positives, 554 false negative, 42 false positive\n",
    "2. 4 layers = 3 relu, last sigmoid\n",
    "    - 0.9713\n",
    "    - 1151 true positives, 552 false negative, 22 false positive\n",
    "3. 5 layers = 4 relu, last sigmoid\n",
    "    - 0.97165\n",
    "    - 1143 true positives, 560 false negative, 7 false positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Observation\n",
    "Most correct predictions are on true negatives for all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework**\n",
    "- Use the dataset: https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset.\n",
    "- Experiment with the number of hidden layers, and the number of units in the hidden layer.\n",
    "- Try to experiment on the activation functions in the hidden layer https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
    "- Try to experiment with the optimizer: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "- Check the accuracy, specificity, and sensitivity of your model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
