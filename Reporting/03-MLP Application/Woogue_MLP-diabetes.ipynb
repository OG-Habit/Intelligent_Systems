{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E0Q3aoKUCRX"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes_prediction_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0             0              1           never  25.19   \n",
       "1      Female  54.0             0              0         No Info  27.32   \n",
       "2        Male  28.0             0              0           never  27.32   \n",
       "3      Female  36.0             0              0         current  23.45   \n",
       "4        Male  76.0             1              1         current  20.14   \n",
       "...       ...   ...           ...            ...             ...    ...   \n",
       "99995  Female  80.0             0              0         No Info  27.32   \n",
       "99996  Female   2.0             0              0         No Info  17.37   \n",
       "99997    Male  66.0             0              0          former  27.83   \n",
       "99998  Female  24.0             0              0           never  35.42   \n",
       "99999  Female  57.0             0              0         current  22.43   \n",
       "\n",
       "       HbA1c_level  blood_glucose_level  diabetes  \n",
       "0              6.6                  140         0  \n",
       "1              6.6                   80         0  \n",
       "2              5.7                  158         0  \n",
       "3              5.0                  155         0  \n",
       "4              4.8                  155         0  \n",
       "...            ...                  ...       ...  \n",
       "99995          6.2                   90         0  \n",
       "99996          6.5                  100         0  \n",
       "99997          5.7                  155         0  \n",
       "99998          4.0                  100         0  \n",
       "99999          6.6                   90         0  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17.37</td>\n",
       "      <td>6.5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Male</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>former</td>\n",
       "      <td>27.83</td>\n",
       "      <td>5.7</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>35.42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Female</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>22.43</td>\n",
       "      <td>6.6</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age hypertension heart_disease smoking_history    bmi  \\\n",
       "0      Female  80.0            0             1           never  25.19   \n",
       "1      Female  54.0            0             0         No Info  27.32   \n",
       "2        Male  28.0            0             0           never  27.32   \n",
       "3      Female  36.0            0             0         current  23.45   \n",
       "4        Male  76.0            1             1         current  20.14   \n",
       "...       ...   ...          ...           ...             ...    ...   \n",
       "99995  Female  80.0            0             0         No Info  27.32   \n",
       "99996  Female   2.0            0             0         No Info  17.37   \n",
       "99997    Male  66.0            0             0          former  27.83   \n",
       "99998  Female  24.0            0             0           never  35.42   \n",
       "99999  Female  57.0            0             0         current  22.43   \n",
       "\n",
       "      HbA1c_level blood_glucose_level  \n",
       "0             6.6                 140  \n",
       "1             6.6                  80  \n",
       "2             5.7                 158  \n",
       "3             5.0                 155  \n",
       "4             4.8                 155  \n",
       "...           ...                 ...  \n",
       "99995         6.2                  90  \n",
       "99996         6.5                 100  \n",
       "99997         5.7                 155  \n",
       "99998         4.0                 100  \n",
       "99999         6.6                  90  \n",
       "\n",
       "[100000 rows x 8 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X, columns = [\"gender\",\"age\",\"hypertension\",\"heart_disease\",\"smoking_history\",\"bmi\",\"HbA1c_level\",\"blood_glucose_level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       diabetes\n",
       "0             0\n",
       "1             0\n",
       "2             0\n",
       "3             0\n",
       "4             0\n",
       "...         ...\n",
       "99995         0\n",
       "99996         0\n",
       "99997         0\n",
       "99998         0\n",
       "99999         0\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y, columns = [\"diabetes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "VYP9cQTWbzuI",
    "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Female', 80.0, 0, ..., 25.19, 6.6, 140],\n",
       "       ['Female', 54.0, 0, ..., 27.32, 6.6, 80],\n",
       "       ['Male', 28.0, 0, ..., 27.32, 5.7, 158],\n",
       "       ...,\n",
       "       ['Male', 66.0, 0, ..., 27.83, 5.7, 155],\n",
       "       ['Female', 24.0, 0, ..., 35.42, 4.0, 100],\n",
       "       ['Female', 57.0, 0, ..., 22.43, 6.6, 90]], dtype=object)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "38vKGE6Nb2RR",
    "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6bQ0UgSU-NJ"
   },
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le5MJreAbW52"
   },
   "source": [
    "Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxVKWXxLbczC"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 0] = le.fit_transform(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "-M1KboxFb6OO",
    "outputId": "e2b8c7e8-0cbc-4cdf-f4eb-7f0853a00b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 80.0 0 ... 25.19 6.6 140]\n",
      " [0 54.0 0 ... 27.32 6.6 80]\n",
      " [1 28.0 0 ... 27.32 5.7 158]\n",
      " ...\n",
      " [1 66.0 0 ... 27.83 5.7 155]\n",
      " [0 24.0 0 ... 35.42 4.0 100]\n",
      " [0 57.0 0 ... 22.43 6.6 90]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUxGZezpbMcb"
   },
   "source": [
    "One Hot Encoding the \"smoking_history\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMXC8-KMVirw"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [4])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "ZcxwEon-b8nV",
    "outputId": "23a98af4-5e33-4b26-c27b-f06e3c5d2baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 0.0 ... 25.19 6.6 140]\n",
      " [1.0 0.0 0.0 ... 27.32 6.6 80]\n",
      " [0.0 0.0 0.0 ... 27.32 5.7 158]\n",
      " ...\n",
      " [0.0 0.0 0.0 ... 27.83 5.7 155]\n",
      " [0.0 0.0 0.0 ... 35.42 4.0 100]\n",
      " [0.0 1.0 0.0 ... 22.43 6.6 90]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zfEzkRVXIwF"
   },
   "source": [
    "## Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the third hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the fourth hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "# ann.add(tf.keras.layers.Dense(units=1, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT4u2S1_Y4WG"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "# layers\n",
    "# 6 units relu\n",
    "# 6 units relu\n",
    "# output layer sigmoid\n",
    "\n",
    "# ann.compile(optimizer = 'adadelta', loss = 'binary_crossentropy', metrics = ['accuracy'])     # stayed pretty much the same at 91.5\n",
    "# ann.compile(optimizer = 'adafactor', loss = 'binary_crossentropy', metrics = ['accuracy'])    # experimental\n",
    "# ann.compile(optimizer = 'adagrad', loss = 'binary_crossentropy', metrics = ['accuracy'])      # 92.21 - 95.53\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])         # 95.85 - 96.61\n",
    "# ann.compile(optimizer = 'adamw', loss = 'binary_crossentropy', metrics = ['accuracy'])        # error\n",
    "# ann.compile(optimizer = 'ftrl', loss = 'binary_crossentropy', metrics = ['accuracy'])         # stuck at 91.50 at all times\n",
    "# ann.compile(optimizer = 'lion', loss = 'binary_crossentropy', metrics = ['accuracy'])         # error\n",
    "# ann.compile(optimizer = 'nadam', loss = 'binary_crossentropy', metrics = ['accuracy'])        # 95.24 - 96.04 2nd epoch to the end basically just stayed the same\n",
    "# ann.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])      # 96.04 stayed the same from 1st to last epoch\n",
    "# ann.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])          # 95.67 - 96.03 was very stagnant starting from epoch 19\n",
    "\n",
    "# adam seems to be the best performing optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2500/2500 [==============================] - 9s 2ms/step - loss: 0.3018 - accuracy: 0.8688\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1391 - accuracy: 0.9469\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1221 - accuracy: 0.9593\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1181 - accuracy: 0.9597\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1162 - accuracy: 0.9602\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1149 - accuracy: 0.9602\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1140 - accuracy: 0.9604\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1133 - accuracy: 0.9606\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1127 - accuracy: 0.9608\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1123 - accuracy: 0.9609\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1119 - accuracy: 0.9609\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1117 - accuracy: 0.9608\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1115 - accuracy: 0.9607\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1113 - accuracy: 0.9609\n",
      "Epoch 15/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1109 - accuracy: 0.9610\n",
      "Epoch 16/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1108 - accuracy: 0.9611\n",
      "Epoch 17/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1106 - accuracy: 0.9610\n",
      "Epoch 18/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1105 - accuracy: 0.9611\n",
      "Epoch 19/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1103 - accuracy: 0.9613\n",
      "Epoch 20/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1101 - accuracy: 0.9614\n",
      "Epoch 21/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1100 - accuracy: 0.9611\n",
      "Epoch 22/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1098 - accuracy: 0.9613\n",
      "Epoch 23/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1097 - accuracy: 0.9611\n",
      "Epoch 24/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1095 - accuracy: 0.9613\n",
      "Epoch 25/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1095 - accuracy: 0.9612\n",
      "Epoch 26/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1093 - accuracy: 0.9612\n",
      "Epoch 27/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1092 - accuracy: 0.9613\n",
      "Epoch 28/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1090 - accuracy: 0.9613\n",
      "Epoch 29/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1088 - accuracy: 0.9611\n",
      "Epoch 30/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1086 - accuracy: 0.9613\n",
      "Epoch 31/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1085 - accuracy: 0.9611\n",
      "Epoch 32/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1082 - accuracy: 0.9613\n",
      "Epoch 33/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1079 - accuracy: 0.9612\n",
      "Epoch 34/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1076 - accuracy: 0.9612\n",
      "Epoch 35/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1073 - accuracy: 0.9616\n",
      "Epoch 36/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1070 - accuracy: 0.9614\n",
      "Epoch 37/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1066 - accuracy: 0.9614\n",
      "Epoch 38/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1063 - accuracy: 0.9614\n",
      "Epoch 39/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1061 - accuracy: 0.9613\n",
      "Epoch 40/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1058 - accuracy: 0.9614\n",
      "Epoch 41/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1055 - accuracy: 0.9615\n",
      "Epoch 42/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1052 - accuracy: 0.9617\n",
      "Epoch 43/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1050 - accuracy: 0.9618\n",
      "Epoch 44/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1047 - accuracy: 0.9615\n",
      "Epoch 45/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1043 - accuracy: 0.9619\n",
      "Epoch 46/100\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1040 - accuracy: 0.9623\n",
      "Epoch 47/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1034 - accuracy: 0.9627\n",
      "Epoch 48/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1027 - accuracy: 0.9631\n",
      "Epoch 49/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1019 - accuracy: 0.9633\n",
      "Epoch 50/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1010 - accuracy: 0.9645\n",
      "Epoch 51/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1000 - accuracy: 0.9652\n",
      "Epoch 52/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0992 - accuracy: 0.9657\n",
      "Epoch 53/100\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.0988 - accuracy: 0.9657\n",
      "Epoch 54/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0983 - accuracy: 0.9661\n",
      "Epoch 55/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0980 - accuracy: 0.9666\n",
      "Epoch 56/100\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0977 - accuracy: 0.9666\n",
      "Epoch 57/100\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 0.0974 - accuracy: 0.9668\n",
      "Epoch 58/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0971 - accuracy: 0.9671\n",
      "Epoch 59/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0968 - accuracy: 0.9669\n",
      "Epoch 60/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0964 - accuracy: 0.9674\n",
      "Epoch 61/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0960 - accuracy: 0.9674\n",
      "Epoch 62/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0956 - accuracy: 0.9679\n",
      "Epoch 63/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0950 - accuracy: 0.9683\n",
      "Epoch 64/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0946 - accuracy: 0.9683\n",
      "Epoch 65/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0941 - accuracy: 0.9687\n",
      "Epoch 66/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0937 - accuracy: 0.9686\n",
      "Epoch 67/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0933 - accuracy: 0.9690\n",
      "Epoch 68/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0930 - accuracy: 0.9692\n",
      "Epoch 69/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0925 - accuracy: 0.9691\n",
      "Epoch 70/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0922 - accuracy: 0.9696\n",
      "Epoch 71/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0918 - accuracy: 0.9694\n",
      "Epoch 72/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0914 - accuracy: 0.9697\n",
      "Epoch 73/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0911 - accuracy: 0.9699\n",
      "Epoch 74/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0907 - accuracy: 0.9701\n",
      "Epoch 75/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0903 - accuracy: 0.9700\n",
      "Epoch 76/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0899 - accuracy: 0.9703\n",
      "Epoch 77/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0896 - accuracy: 0.9703\n",
      "Epoch 78/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0890 - accuracy: 0.9704\n",
      "Epoch 79/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0886 - accuracy: 0.9707\n",
      "Epoch 80/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0882 - accuracy: 0.9705\n",
      "Epoch 81/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0878 - accuracy: 0.9707\n",
      "Epoch 82/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0874 - accuracy: 0.9707\n",
      "Epoch 83/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0870 - accuracy: 0.9708\n",
      "Epoch 84/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0866 - accuracy: 0.9709\n",
      "Epoch 85/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0861 - accuracy: 0.9709\n",
      "Epoch 86/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0859 - accuracy: 0.9711\n",
      "Epoch 87/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0857 - accuracy: 0.9711\n",
      "Epoch 88/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0854 - accuracy: 0.9711\n",
      "Epoch 89/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0851 - accuracy: 0.9710\n",
      "Epoch 90/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0849 - accuracy: 0.9711\n",
      "Epoch 91/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0846 - accuracy: 0.9711\n",
      "Epoch 92/100\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 0.0845 - accuracy: 0.9712\n",
      "Epoch 93/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0843 - accuracy: 0.9712\n",
      "Epoch 94/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0842 - accuracy: 0.9712\n",
      "Epoch 95/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0840 - accuracy: 0.9712\n",
      "Epoch 96/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0839 - accuracy: 0.9711\n",
      "Epoch 97/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0837 - accuracy: 0.9713\n",
      "Epoch 98/100\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0837 - accuracy: 0.9713\n",
      "Epoch 99/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.0835 - accuracy: 0.9714\n",
      "Epoch 100/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.0834 - accuracy: 0.9713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x13b4be584d0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.adam.Adam at 0x13b4beb4050>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "## Part 4 - Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/625 [..............................] - ETA: 1:14"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0oyfLWoaEGw"
   },
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ci6K_r6LaF6P",
    "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18255    42]\n",
      " [  554  1149]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9702"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x750 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ann.compile(optimizer = 'adadelta', loss = 'binary_crossentropy', metrics = ['accuracy'])     0 true positives, 0 false positive, 18297 on true negatives\n",
    "ann.compile(optimizer = 'adafactor', loss = 'binary_crossentropy', metrics = ['accuracy'])    experimental\n",
    "ann.compile(optimizer = 'adagrad', loss = 'binary_crossentropy', metrics = ['accuracy'])      92.21 - 95.53\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])         95.85 - 96.61\n",
    "ann.compile(optimizer = 'adamw', loss = 'binary_crossentropy', metrics = ['accuracy'])        error\n",
    "ann.compile(optimizer = 'ftrl', loss = 'binary_crossentropy', metrics = ['accuracy'])         0 true positives, 0 false positive, good true negative\n",
    "ann.compile(optimizer = 'lion', loss = 'binary_crossentropy', metrics = ['accuracy'])         error\n",
    "ann.compile(optimizer = 'nadam', loss = 'binary_crossentropy', metrics = ['accuracy'])        581 false negative, 198 false positive\n",
    "ann.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])      517 false negative, 371 false positive, 1186 true positive\n",
    "ann.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])          505 false negative, 382 false positive, 1198 true positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (32, 6)                   84        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (32, 6)                   42        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (32, 1)                   7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133 (532.00 Byte)\n",
      "Trainable params: 133 (532.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using adam optimizer\n",
    "1. 3 layers - all relu\n",
    "    - 0.97245\n",
    "    - 0 false positives, 1152 true positive, 551 false negative\n",
    "2. 3 layers - all sigmoid\n",
    "    - 0.9702\n",
    "    - 1149 true positives, 554 false negative, 42 false positive\n",
    "2. 4 layers = 3 relu, last sigmoid\n",
    "    - 0.9713\n",
    "    - 1151 true positives, 552 false negative, 22 false positive\n",
    "3. 5 layers = 4 relu, last sigmoid\n",
    "    - 0.97165\n",
    "    - 1143 true positives, 560 false negative, 7 false positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Observation\n",
    "Most correct predictions are on true negatives for all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework**\n",
    "- Use the dataset: https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset.\n",
    "- Experiment with the number of hidden layers, and the number of units in the hidden layer.\n",
    "- Try to experiment on the activation functions in the hidden layer https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
    "- Try to experiment with the optimizer: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "- Check the accuracy, specificity, and sensitivity of your model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
